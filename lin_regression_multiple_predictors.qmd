# Linear regression notation for models with multiple predictors

```{python}
# Import numerical and plotting libraries
import numpy as np
import numpy.linalg as npl
import matplotlib.pyplot as plt
import pandas as pd

# For displaying variables in mathematical form.
from jupyprint import jupyprint, arraytex

# For interactive widgets.
from ipywidgets import interact

from IPython.display import display, Markdown

jupyprint = lambda s : display(Markdown(s))
```

```{python}
education = np.array([ 86,  76,  92,  90,  86,  84,  93, 100,  87,  86,
74,
                      98,  97, 84,  91])
prestige = np.array([82, 83, 90, 76, 90, 87, 93, 90, 52, 88, 57, 89, 97, 59, 73])
income = np.array([62, 72, 75, 55, 64, 21, 64, 80, 67, 72, 42, 76, 76, 41, 48])
```

```{python}
def interactive_notation(edu_slope_guess=1,
                         inc_slope_guess=1,
                         intercept_guess=1):

    # calculate the fitted values, for this combination of parameter estimates
    fitted = edu_slope_guess * education + inc_slope_guess * income + intercept_guess

    # calculate the errors, for this combination of parameter estimates
    errors = prestige - fitted

    # do not worry about this code, it just prints the mathematical notation below this cell
    jupyprint("$\\vec{\\hat{y}} = b_1 * $ `education` + $b_2 * $ `income` +   $\\text{c} $")
    jupyprint(f"The sum of the squared errors for this combination of parameter estimates is <b> {round(np.sum(errors**2), 2)} </b>")

interact(interactive_notation, edu_slope_guess = (-1, 1, 0.1), inc_slope_guess = (-1, 1, 0.1), intercept_guess = (-10, 10, 0.1))
```
